---
title: "リファレンス: OpenAI Realtime Voice | Voice Providers | Mastra ドキュメント"
description: "OpenAIRealtimeVoice クラスのドキュメント。WebSocket を通じてリアルタイムのテキスト読み上げおよび音声認識機能を提供します。"
---

# OpenAI Realtime Voice

OpenAIRealtimeVoice クラスは、OpenAI の WebSocket ベースの API を使用してリアルタイムの音声対話機能を提供します。リアルタイムの音声から音声への変換、音声活動検出、イベントベースの音声ストリーミングをサポートしています。

## 使用例

```typescript
import { OpenAIRealtimeVoice } from "@mastra/voice-openai-realtime";
import { playAudio, getMicrophoneStream } from "@mastra/node-audio";

// Initialize with default configuration using environment variables
const voice = new OpenAIRealtimeVoice();

// Or initialize with specific configuration
const voiceWithConfig = new OpenAIRealtimeVoice({
  apiKey: "your-openai-api-key",
  model: "gpt-4o-mini-realtime-preview-2024-12-17",
  speaker: "alloy", // Default voice
});

voiceWithConfig.updateSession({
  turn_detection: {
    type: "server_vad",
    threshold: 0.6,
    silence_duration_ms: 1200,
  },
});

// Establish connection
await voice.connect();

// Set up event listeners
voice.on("speaker", ({ audio }) => {
  // Handle audio data (Int16Array) pcm format by default
  playAudio(audio);
});

voice.on("writing", ({ text, role }) => {
  // Handle transcribed text
  console.log(`${role}: ${text}`);
});

// Convert text to speech
await voice.speak("Hello, how can I help you today?", {
  speaker: "echo", // Override default voice
});

// Process audio input
const microphoneStream = getMicrophoneStream();
await voice.send(microphoneStream);

// When done, disconnect
voice.connect();
```

## 設定

### コンストラクタオプション

<PropertiesTable
  content={[
    {
      name: "model",
      type: "string",
      description: "リアルタイム音声対話に使用するモデルID。",
      isOptional: true,
      defaultValue: "'gpt-4o-mini-realtime-preview-2024-12-17'",
    },
    {
      name: "apiKey",
      type: "string",
      description:
        "OpenAI APIキー。OPENAI_API_KEY環境変数にフォールバックします。",
      isOptional: true,
    },
    {
      name: "speaker",
      type: "string",
      description: "音声合成のデフォルトボイスID。",
      isOptional: true,
      defaultValue: "'alloy'",
    },
  ]}
/>

### 音声アクティビティ検出（VAD）設定

<PropertiesTable
  content={[
    {
      name: "type",
      type: "string",
      description:
        "使用するVADのタイプ。サーバーサイドVADはより高い精度を提供します。",
      isOptional: true,
      defaultValue: "'server_vad'",
    },
    {
      name: "threshold",
      type: "number",
      description: "音声検出の感度（0.0-1.0）。",
      isOptional: true,
      defaultValue: "0.5",
    },
    {
      name: "prefix_padding_ms",
      type: "number",
      description:
        "音声が検出される前に含める音声のミリ秒数。",
      isOptional: true,
      defaultValue: "1000",
    },
    {
      name: "silence_duration_ms",
      type: "number",
      description: "ターンを終了する前の無音のミリ秒数。",
      isOptional: true,
      defaultValue: "1000",
    },
  ]}
/>

## メソッド

### connect()

OpenAI リアルタイムサービスへの接続を確立します。speak、listen、send 関数を使用する前に呼び出す必要があります。

<PropertiesTable
  content={[
    {
      name: "returns",
      type: "Promise<void>",
      description: "接続が確立されたときに解決される Promise。",
    },
  ]}
/>

### speak()

設定された音声モデルを使用して発話イベントを発行します。入力として文字列またはリーダブルストリームのいずれかを受け付けます。

<PropertiesTable
  content={[
    {
      name: "input",
      type: "string | NodeJS.ReadableStream",
      description: "音声に変換するテキストまたはテキストストリーム。",
      isOptional: false,
    },
    {
      name: "options.speaker",
      type: "string",
      description: "この特定の発話リクエストで使用する音声 ID。",
      isOptional: true,
      defaultValue: "Constructor's speaker value",
    },
  ]}
/>

戻り値: `Promise<void>`

### listen()

音声認識のために音声入力を処理します。音声データのリーダブルストリームを受け取り、書き起こされたテキストとともに 'listening' イベントを発行します。

<PropertiesTable
  content={[
    {
      name: "audioData",
      type: "NodeJS.ReadableStream",
      description: "書き起こし対象の音声ストリーム。",
      isOptional: false,
    },
  ]}
/>

戻り値: `Promise<void>`

### send()

ライブマイク入力など、連続的な音声ストリーミングシナリオのために、音声データをリアルタイムで OpenAI サービスにストリーミングします。

<PropertiesTable
  content={[
    {
      name: "audioData",
      type: "NodeJS.ReadableStream",
      description: "サービスに送信する音声ストリーム。",
      isOptional: false,
    },
  ]}
/>

戻り値: `Promise<void>`

### updateConfig()

音声インスタンスのセッション設定を更新します。これにより、音声設定やターン検出、その他のパラメータを変更できます。

<PropertiesTable
  content={[
    {
      name: "sessionConfig",
      type: "Realtime.SessionConfig",
      description: "適用する新しいセッション設定。",
      isOptional: false,
    },
  ]}
/>

戻り値: `void`

### addTools()

音声インスタンスにツールセットを追加します。ツールを追加することで、モデルが会話中に追加のアクションを実行できるようになります。OpenAIRealtimeVoice が Agent に追加されている場合、Agent に設定されたツールは自動的に音声インターフェースでも利用可能になります。

<PropertiesTable
  content={[
    {
      name: "tools",
      type: "ToolsInput",
      description: "装備するツールの設定。",
      isOptional: true,
    },
  ]}
/>

戻り値: `void`

### close()

OpenAI リアルタイムセッションから切断し、リソースをクリーンアップします。音声インスタンスの使用が終了したら呼び出してください。

戻り値: `void`

### getSpeakers()

利用可能な音声スピーカーのリストを返します。

戻り値: `Promise<Array<{ voiceId: string; [key: string]: any }>>`

### on()

音声イベントのイベントリスナーを登録します。

<PropertiesTable
  content={[
    {
      name: "event",
      type: "string",
      description: "リッスンするイベント名。",
      isOptional: false,
    },
    {
      name: "callback",
      type: "Function",
      description: "イベントが発生したときに呼び出す関数。",
      isOptional: false,
    },
  ]}
/>

戻り値: `void`

### off()

以前に登録したイベントリスナーを削除します。

<PropertiesTable
  content={[
    {
      name: "event",
      type: "string",
      description: "リッスンを停止するイベント名。",
      isOptional: false,
    },
    {
      name: "callback",
      type: "Function",
      description: "削除する特定のコールバック関数。",
      isOptional: false,
    },
  ]}
/>

戻り値: `void`

## イベント

OpenAIRealtimeVoiceクラスは以下のイベントを発生させます：

<PropertiesTable
  content={[
    {
      name: "speaking",
      type: "event",
      description:
        "モデルから音声データを受信したときに発生します。コールバックは { audio: Int16Array } を受け取ります。",
    },
    {
      name: "writing",
      type: "event",
      description:
        "文字起こしされたテキストが利用可能になったときに発生します。コールバックは { text: string, role: string } を受け取ります。",
    },
    {
      name: "error",
      type: "event",
      description:
        "エラーが発生したときに発生します。コールバックはエラーオブジェクトを受け取ります。",
    },
  ]}
/>

### OpenAI Realtimeイベント

[OpenAI Realtimeユーティリティイベント](https://github.com/openai/openai-realtime-api-beta#reference-client-utility-events)も'openAIRealtime:'を接頭辞として付けることでリッスンできます：

<PropertiesTable
  content={[
    {
      name: "openAIRealtime:conversation.created",
      type: "event",
      description: "新しい会話が作成されたときに発生します。",
    },
    {
      name: "openAIRealtime:conversation.interrupted",
      type: "event",
      description: "会話が中断されたときに発生します。",
    },
    {
      name: "openAIRealtime:conversation.updated",
      type: "event",
      description: "会話が更新されたときに発生します。",
    },
    {
      name: "openAIRealtime:conversation.item.appended",
      type: "event",
      description: "アイテムが会話に追加されたときに発生します。",
    },
    {
      name: "openAIRealtime:conversation.item.completed",
      type: "event",
      description: "会話内のアイテムが完了したときに発生します。",
    },
  ]}
/>

## 利用可能な音声

以下の音声オプションが利用できます：

- `alloy`: ニュートラルでバランスが取れている
- `ash`: クリアで正確
- `ballad`: メロディックで滑らか
- `coral`: 暖かく親しみやすい
- `echo`: 共鳴して深みがある
- `sage`: 落ち着いて思慮深い
- `shimmer`: 明るくエネルギッシュ
- `verse`: 多才で表現力豊か

## メモ

- APIキーはコンストラクタオプションまたは`OPENAI_API_KEY`環境変数を通じて提供できます
- OpenAI リアルタイム音声APIはリアルタイム通信にWebSocketsを使用しています
- サーバーサイドの音声アクティビティ検出（VAD）は音声検出のための精度が向上します
- すべての音声データはInt16Array形式で処理されます
- 音声インスタンスは他のメソッドを使用する前に`connect()`で接続する必要があります
- 終了時には必ず`close()`を呼び出してリソースを適切にクリーンアップしてください
- メモリ管理はOpenAI リアルタイムAPIによって処理されます
